title: "PLM"
author: "jene"
date: "20 de junio de 2019"
output: html_document
---
##introducción
```{r}

```

Este proyecto utiliza un comjunto de  datos de ejercicios de levantamiento de pesas para desarrollar y probar un modelo de reconocimiento/predicción de actividad humana. En particular, el objetivo de este proyecto es reconocer y/0 predecir la manera en que los usuarios de un conjunto de sensores corporales hicieron el ejercicio de levantamiento de pesas. Procesará los datos de acelerómetros en la banda, antebrazo, brazo y Dumbell de 6 participantes que realizaron barbell ascensores correctamente y de forma incorrecta de 5 maneras diferentes.
```
library(knitr)
library(caret)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
library(corrplot)
library(doParallel)
library(dplyr)
library(e1071)
##install.packages("dplyr")
##install.packages("lubridate")
```

# leendo  los datos
```{r}
training <- read.csv("C:/r/Machear learning/Proyecto a enviar/pml-training.csv",  na.strings=c("NA","#DIV/0!",""), header = TRUE)
testing <- read.csv("C:/r/Machear learning/Proyecto a enviar/pml-testing.csv",  na.strings=c("NA","#DIV/0!",""), header = TRUE)
dim(training)
```
```{r}
str(training)
```

#  Limpieza de los datos
elimanado los espacios en blanco y los NA

```{r}
training<- training[, colSums(is.na(training)) == 0]
dim(training)
```

```{r}
testing<- testing[, colSums(is.na(testing)) == 0]
dim(testing)
```



```{r}
#borrando las site primeras columnas
training1 <- training[, -c(1:7)]
dim(training1)

testing1 <- testing[, -c(1:7)]
dim(testing1)

```

## division de los datos 

Aquí divido la data  en dos subgrupos: entrenamiento (80%) y pruebas  (20%) conjuntos de datos.
```{r partition, cache=TRUE}
library(caret)
library(lubridate)
 set.seed (12345)
indexTrain <- createDataPartition(y = training1$classe, p=0.8, list = FALSE)
train <- training1[indexTrain,]
test <- training1[-indexTrain,]
dim(train)
```


## Prediccion con clasificacion tres
Aquí construyo un modelo de árbol con una validación cruzada de 5 pliegues 

```{r}
library(dplyr)

tr_control <- trainControl(method="cv", number = 5)
model_tree <- train(classe ~ ., data = train, method = "rpart", trControl = tr_control)
fancyRpartPlot(model_tree$finalModel)
pred_train <- predict(model_tree, newdata = train)
confMatrix_train <- confusionMatrix(train$classe, pred_train)
confMatrix_train$table
confMatrix_train$overall[1]
pred_test <- predict(model_tree, newdata = test)
confMatrix_test <- confusionMatrix(test$classe, pred_test)
confMatrix_test$table
confMatrix_test$overall[1]
```




## Prediction with Random Forests
```{r}
library(randomForest)
tr_control <- trainControl(method="cv", number = 5)
model_forest <- train(classe ~ ., data = train, method="rf", trControl = tr_control)
model_forest$finalModel

pred_train <- predict(model_forest, newdata = train)
confMatrix_train <- confusionMatrix(train$classe, pred_train)
confMatrix_train$table
confMatrix_train$overall[1]

pred_test <- predict(model_forest, newdata = test)
confMatrix_test <- confusionMatrix(test$classe, pred_test)
confMatrix_test$table
confMatrix_test$overall[1]
```
la precisión   es 0.9913332

#Boosted Model


```{r}
# model fit
set.seed(12345)
Boosted <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
model  <- train(classe ~ ., data=train, method = "gbm",
        trControl = Boosted, verbose = FALSE)
model$finalModel
```

```{r}
# prediction on Test dataset
pred <- predict(GBM, newdata=test)
CM <- confusionMatrix(pred, test$classe)
CM
```
# plot matrix results
```{r}

plot(CM$table, col = CM$byClass, 
     main = paste("Precision=", round(CM$overall['Accuracy'], 4)))
```


## Conclusión
El árbol de clasificación El resulatodo era muy pobare  debido a los usos de muchas variables
El Random Forests es el mas optimo
