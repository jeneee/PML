---
title: "PLM"
author: "jene"
date: "28 de junio de 2019"
output: html_document
---

```{r}
library(knitr)
library(caret)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
library(corrplot)
library(doParallel)
library(dplyr)
#library(e1071)
##install.packages("dplyr")
##install.packages("lubridate")


```

## R Markdown

Este proyecto utiliza un comjunto de  datos de ejercicios de levantamiento de pesas para desarrollar y probar un modelo de reconocimiento y prediccion de actividad humana. En particular, el objetivo de este proyecto es reconocer y predecir la manera en que los usuarios de un conjunto de sensores corporales hicieron el ejercicio de levantamiento de pesas. Procesara los datos de acelerometros en la banda, antebrazo, brazo y Dumbell de 6 participantes que realizaron barbell ascensores correctamente y de forma incorrecta de 5 maneras diferentes.


## leyendo  los datos
```{r}
training <- read.csv("C:/r/Machear learning/Proyecto a enviar/pml-training.csv",  na.strings=c("NA","#DIV/0!",""), header = TRUE)
testing <- read.csv("C:/r/Machear learning/Proyecto a enviar/pml-testing.csv",  na.strings=c("NA","#DIV/0!",""), header = TRUE)
dim(training)
```

```{r}
str(training)
```

#  Limpieza de los datos
Elimanado los espacios en blanco y los NA

```{r}
training<- training[, colSums(is.na(training)) == 0]
dim(training)
```

```{r}
testing<- testing[, colSums(is.na(testing)) == 0]
dim(testing)
```





#borrando las site primeras columnas
```{r}
training1 <- training[, -c(1:7)]
dim(training1)
testing1 <- testing[, -c(1:7)]
dim(testing1)
```

## division de los datos 
Se divido la data  en dos subgrupos: entrenamiento (80%) y pruebas  (20%) conjuntos de datos.
```{r partition, cache=TRUE}
library(caret)
#library(lubridate)
 set.seed (12345)
indexTrain <- createDataPartition(y = training1$classe, p=0.8, list = FALSE)
train <- training1[indexTrain,]
test <- training1[-indexTrain,]
dim(train)
```


## Prediccion con clasificacion tres
Se construyo un modelo de arbol con una validacion cruzada de 5 pliegues 

```{r}
library(knitr)
library(caret)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
library(corrplot)
library(doParallel)
library(dplyr)
set.seed(12345)
tr_control <- trainControl(method="cv", number = 5)
model_tree <- train(classe ~ ., data = train, method = "rpart", trControl = tr_control)
fancyRpartPlot(model_tree$finalModel)
pred_train <- predict(model_tree, newdata = train)
confMatrix_train <- confusionMatrix(train$classe, pred_train)
confMatrix_train$table
confMatrix_train$overall[1]
pred_test <- predict(model_tree, newdata = test)
confMatrix_test <- confusionMatrix(test$classe, pred_test)
confMatrix_test$table
confMatrix_test$overall[1]

```



## Prediction with Random Forests
```{r}
library(randomForest)
tr_control <- trainControl(method="cv", number = 5)
model_forest <- train(classe ~ ., data = train, method="rf", trControl = tr_control)
model_forest$finalModel
pred_train <- predict(model_forest, newdata = train)
confMatrix_train <- confusionMatrix(train$classe, pred_train)
confMatrix_train$table
confMatrix_train$overall[1]
pred_test <- predict(model_forest, newdata = test)
confMatrix_test <- confusionMatrix(test$classe, pred_test)
confMatrix_test$table
confMatrix_test$overall[1]
```
la precision del modelo forest   es 0.9913332

#Boosted Model


```{r}
set.seed(12345)
Boosted <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
model  <- train(classe ~ ., data=train, method = "gbm",
        trControl = Boosted, verbose = FALSE)
model$finalModel
```

```{r}
# prediction on Test dataset
pred <- predict(model, newdata=test)
CM <- confusionMatrix(pred, test$classe)
CM
```
# plot matrix results
```{r}
plot(CM$table, col = CM$byClass, 
     main = paste("Precision=", round(CM$overall['Accuracy'], 4)))
```


## Conclusion
El arbol de clasificacion El resulatodo era muy pobare  debido a los usos de muchas variables
El Random Forests es el mas optimo
